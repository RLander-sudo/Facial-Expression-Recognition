{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00091313-35d8-4df6-8d14-1ed918192025",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Train set: (25838, 48, 48, 1)\n",
      "Validation set: (2871, 48, 48, 1)\n",
      "Number of classes: 7\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 48, 48, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 48, 48, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 24, 24, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 24, 24, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 12, 12, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 12, 12, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 6, 6, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 6, 6, 128)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               1179904   \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1276295 (4.87 MB)\n",
      "Trainable params: 1275335 (4.87 MB)\n",
      "Non-trainable params: 960 (3.75 KB)\n",
      "_________________________________________________________________\n",
      "\n",
      "Training optimized model...\n",
      "Epoch 1/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 2.1345 - accuracy: 0.2437     \n",
      "Epoch 1: val_accuracy improved from -inf to 0.18182, saving model to ../models\\expression_model_20250509-093652.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\anaconda3\\envs\\myEnv\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 315s 755ms/step - loss: 2.1345 - accuracy: 0.2437 - val_loss: 2.6518 - val_accuracy: 0.1818 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.7050 - accuracy: 0.3412  \n",
      "Epoch 2: val_accuracy improved from 0.18182 to 0.38070, saving model to ../models\\expression_model_20250509-093652.h5\n",
      "404/404 [==============================] - 301s 746ms/step - loss: 1.7050 - accuracy: 0.3412 - val_loss: 1.6096 - val_accuracy: 0.3807 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.5571 - accuracy: 0.3906  \n",
      "Epoch 3: val_accuracy improved from 0.38070 to 0.38488, saving model to ../models\\expression_model_20250509-093652.h5\n",
      "404/404 [==============================] - 304s 752ms/step - loss: 1.5571 - accuracy: 0.3906 - val_loss: 1.6694 - val_accuracy: 0.3849 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.4783 - accuracy: 0.4231  \n",
      "Epoch 4: val_accuracy did not improve from 0.38488\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "404/404 [==============================] - 298s 738ms/step - loss: 1.4783 - accuracy: 0.4231 - val_loss: 1.7618 - val_accuracy: 0.3448 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.4209 - accuracy: 0.4438  \n",
      "Epoch 5: val_accuracy improved from 0.38488 to 0.42424, saving model to ../models\\expression_model_20250509-093652.h5\n",
      "404/404 [==============================] - 302s 747ms/step - loss: 1.4209 - accuracy: 0.4438 - val_loss: 1.5264 - val_accuracy: 0.4242 - lr: 5.0000e-04\n",
      "Epoch 6/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.3629 - accuracy: 0.4661  \n",
      "Epoch 6: val_accuracy improved from 0.42424 to 0.46325, saving model to ../models\\expression_model_20250509-093652.h5\n",
      "404/404 [==============================] - 299s 741ms/step - loss: 1.3629 - accuracy: 0.4661 - val_loss: 1.3994 - val_accuracy: 0.4633 - lr: 5.0000e-04\n",
      "Epoch 7/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.3264 - accuracy: 0.4696  \n",
      "Epoch 7: val_accuracy did not improve from 0.46325\n",
      "404/404 [==============================] - 298s 737ms/step - loss: 1.3264 - accuracy: 0.4696 - val_loss: 1.4091 - val_accuracy: 0.4573 - lr: 5.0000e-04\n",
      "Epoch 8/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.2932 - accuracy: 0.4851  \n",
      "Epoch 8: val_accuracy improved from 0.46325 to 0.48659, saving model to ../models\\expression_model_20250509-093652.h5\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "404/404 [==============================] - 313s 774ms/step - loss: 1.2932 - accuracy: 0.4851 - val_loss: 1.4016 - val_accuracy: 0.4866 - lr: 5.0000e-04\n",
      "Epoch 9/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.2514 - accuracy: 0.5021  \n",
      "Epoch 9: val_accuracy improved from 0.48659 to 0.50296, saving model to ../models\\expression_model_20250509-093652.h5\n",
      "404/404 [==============================] - 312s 773ms/step - loss: 1.2514 - accuracy: 0.5021 - val_loss: 1.3015 - val_accuracy: 0.5030 - lr: 2.5000e-04\n",
      "Epoch 10/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.2155 - accuracy: 0.5115  \n",
      "Epoch 10: val_accuracy did not improve from 0.50296\n",
      "404/404 [==============================] - 311s 770ms/step - loss: 1.2155 - accuracy: 0.5115 - val_loss: 1.3548 - val_accuracy: 0.4925 - lr: 2.5000e-04\n",
      "Epoch 11/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.1867 - accuracy: 0.5177  \n",
      "Epoch 11: val_accuracy improved from 0.50296 to 0.51689, saving model to ../models\\expression_model_20250509-093652.h5\n",
      "404/404 [==============================] - 314s 777ms/step - loss: 1.1867 - accuracy: 0.5177 - val_loss: 1.2744 - val_accuracy: 0.5169 - lr: 2.5000e-04\n",
      "Epoch 12/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.1727 - accuracy: 0.5262  \n",
      "Epoch 12: val_accuracy improved from 0.51689 to 0.52212, saving model to ../models\\expression_model_20250509-093652.h5\n",
      "404/404 [==============================] - 312s 772ms/step - loss: 1.1727 - accuracy: 0.5262 - val_loss: 1.2696 - val_accuracy: 0.5221 - lr: 2.5000e-04\n",
      "Epoch 13/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.1439 - accuracy: 0.5324  \n",
      "Epoch 13: val_accuracy did not improve from 0.52212\n",
      "404/404 [==============================] - 315s 779ms/step - loss: 1.1439 - accuracy: 0.5324 - val_loss: 1.2917 - val_accuracy: 0.4998 - lr: 2.5000e-04\n",
      "Epoch 14/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.1420 - accuracy: 0.5367  \n",
      "Epoch 14: val_accuracy did not improve from 0.52212\n",
      "404/404 [==============================] - 308s 762ms/step - loss: 1.1420 - accuracy: 0.5367 - val_loss: 1.2563 - val_accuracy: 0.5200 - lr: 2.5000e-04\n",
      "Epoch 15/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.1287 - accuracy: 0.5398  \n",
      "Epoch 15: val_accuracy did not improve from 0.52212\n",
      "404/404 [==============================] - 301s 745ms/step - loss: 1.1287 - accuracy: 0.5398 - val_loss: 1.2623 - val_accuracy: 0.5218 - lr: 2.5000e-04\n",
      "Epoch 16/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.1094 - accuracy: 0.5470  \n",
      "Epoch 16: val_accuracy did not improve from 0.52212\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "404/404 [==============================] - 293s 724ms/step - loss: 1.1094 - accuracy: 0.5470 - val_loss: 1.2669 - val_accuracy: 0.5113 - lr: 2.5000e-04\n",
      "Epoch 17/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.0785 - accuracy: 0.5570  \n",
      "Epoch 17: val_accuracy improved from 0.52212 to 0.52281, saving model to ../models\\expression_model_20250509-093652.h5\n",
      "404/404 [==============================] - 296s 733ms/step - loss: 1.0785 - accuracy: 0.5570 - val_loss: 1.2473 - val_accuracy: 0.5228 - lr: 1.2500e-04\n",
      "Epoch 18/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.0664 - accuracy: 0.5630  \n",
      "Epoch 18: val_accuracy improved from 0.52281 to 0.53117, saving model to ../models\\expression_model_20250509-093652.h5\n",
      "404/404 [==============================] - 296s 733ms/step - loss: 1.0664 - accuracy: 0.5630 - val_loss: 1.2111 - val_accuracy: 0.5312 - lr: 1.2500e-04\n",
      "Epoch 19/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.0547 - accuracy: 0.5653  \n",
      "Epoch 19: val_accuracy improved from 0.53117 to 0.53361, saving model to ../models\\expression_model_20250509-093652.h5\n",
      "404/404 [==============================] - 296s 732ms/step - loss: 1.0547 - accuracy: 0.5653 - val_loss: 1.2152 - val_accuracy: 0.5336 - lr: 1.2500e-04\n",
      "Epoch 20/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.0480 - accuracy: 0.5655  \n",
      "Epoch 20: val_accuracy improved from 0.53361 to 0.53675, saving model to ../models\\expression_model_20250509-093652.h5\n",
      "404/404 [==============================] - 292s 724ms/step - loss: 1.0480 - accuracy: 0.5655 - val_loss: 1.2053 - val_accuracy: 0.5367 - lr: 1.2500e-04\n",
      "Epoch 21/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.0317 - accuracy: 0.5723  \n",
      "Epoch 21: val_accuracy improved from 0.53675 to 0.54127, saving model to ../models\\expression_model_20250509-093652.h5\n",
      "404/404 [==============================] - 329s 814ms/step - loss: 1.0317 - accuracy: 0.5723 - val_loss: 1.2045 - val_accuracy: 0.5413 - lr: 1.2500e-04\n",
      "Epoch 22/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.0265 - accuracy: 0.5713  \n",
      "Epoch 22: val_accuracy did not improve from 0.54127\n",
      "404/404 [==============================] - 304s 752ms/step - loss: 1.0265 - accuracy: 0.5713 - val_loss: 1.1995 - val_accuracy: 0.5413 - lr: 1.2500e-04\n",
      "Epoch 23/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.0301 - accuracy: 0.5767  \n",
      "Epoch 23: val_accuracy improved from 0.54127 to 0.54615, saving model to ../models\\expression_model_20250509-093652.h5\n",
      "404/404 [==============================] - 299s 740ms/step - loss: 1.0301 - accuracy: 0.5767 - val_loss: 1.2156 - val_accuracy: 0.5462 - lr: 1.2500e-04\n",
      "Epoch 24/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.0263 - accuracy: 0.5742  \n",
      "Epoch 24: val_accuracy improved from 0.54615 to 0.54754, saving model to ../models\\expression_model_20250509-093652.h5\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "404/404 [==============================] - 302s 747ms/step - loss: 1.0263 - accuracy: 0.5742 - val_loss: 1.2195 - val_accuracy: 0.5475 - lr: 1.2500e-04\n",
      "Epoch 25/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.0154 - accuracy: 0.5810  \n",
      "Epoch 25: val_accuracy did not improve from 0.54754\n",
      "404/404 [==============================] - 300s 741ms/step - loss: 1.0154 - accuracy: 0.5810 - val_loss: 1.1991 - val_accuracy: 0.5434 - lr: 6.2500e-05\n",
      "Epoch 26/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 0.9929 - accuracy: 0.5842  \n",
      "Epoch 26: val_accuracy did not improve from 0.54754\n",
      "404/404 [==============================] - 298s 738ms/step - loss: 0.9929 - accuracy: 0.5842 - val_loss: 1.1869 - val_accuracy: 0.5475 - lr: 6.2500e-05\n",
      "Epoch 27/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 0.9903 - accuracy: 0.5879  \n",
      "Epoch 27: val_accuracy improved from 0.54754 to 0.54824, saving model to ../models\\expression_model_20250509-093652.h5\n",
      "404/404 [==============================] - 302s 746ms/step - loss: 0.9903 - accuracy: 0.5879 - val_loss: 1.1757 - val_accuracy: 0.5482 - lr: 6.2500e-05\n",
      "Epoch 28/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 0.9839 - accuracy: 0.5891  \n",
      "Epoch 28: val_accuracy improved from 0.54824 to 0.54998, saving model to ../models\\expression_model_20250509-093652.h5\n",
      "404/404 [==============================] - 317s 786ms/step - loss: 0.9839 - accuracy: 0.5891 - val_loss: 1.1855 - val_accuracy: 0.5500 - lr: 6.2500e-05\n",
      "Epoch 29/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 0.9857 - accuracy: 0.5913  \n",
      "Epoch 29: val_accuracy improved from 0.54998 to 0.55381, saving model to ../models\\expression_model_20250509-093652.h5\n",
      "404/404 [==============================] - 302s 749ms/step - loss: 0.9857 - accuracy: 0.5913 - val_loss: 1.1704 - val_accuracy: 0.5538 - lr: 6.2500e-05\n",
      "Epoch 30/30\n",
      "404/404 [==============================] - ETA: 0s - loss: 0.9773 - accuracy: 0.5945  \n",
      "Epoch 30: val_accuracy improved from 0.55381 to 0.55416, saving model to ../models\\expression_model_20250509-093652.h5\n",
      "404/404 [==============================] - 296s 733ms/step - loss: 0.9773 - accuracy: 0.5945 - val_loss: 1.1768 - val_accuracy: 0.5542 - lr: 6.2500e-05\n",
      "\n",
      "Model saved to: ../models/expression_model_20250509-093652.h5\n",
      "Training history saved to: ../models/training_history_20250509-093652.pkl\n",
      "\n",
      "Final Train Accuracy: 0.5945\n",
      "Final Val Accuracy: 0.5542\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# Facial Expression Recognition - Optimized Training\n",
    "# Notebook 2 (Optimized): Lightweight CNN + Callbacks + Class Weights\n",
    "# ---------------------------------------------\n",
    "\n",
    "# 1. Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# 2. Load preprocessed data\n",
    "print(\"Loading datasets...\")\n",
    "X_train = np.load('../data/X_train.npy')\n",
    "X_val = np.load('../data/X_val.npy')\n",
    "y_train = np.load('../data/y_train.npy')  # One-hot encoded\n",
    "y_val = np.load('../data/y_val.npy')\n",
    "\n",
    "with open('../data/class_weight.pkl', 'rb') as f:\n",
    "    class_weight_dict = pickle.load(f)\n",
    "\n",
    "with open('../data/class_names.pkl', 'rb') as f:\n",
    "    class_names = pickle.load(f)\n",
    "\n",
    "print(\"Train set:\", X_train.shape)\n",
    "print(\"Validation set:\", X_val.shape)\n",
    "print(\"Number of classes:\", len(class_names))\n",
    "\n",
    "# 3. Optimized CNN Model\n",
    "def build_optimized_model(input_shape=(48, 48, 1), num_classes=7):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        \n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Dropout(0.4),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_optimized_model(input_shape=(48, 48, 1), num_classes=len(class_names))\n",
    "\n",
    "# 4. Compile\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 5. Callbacks\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_path = f'../models/expression_model_{timestamp}.h5'\n",
    "\n",
    "callbacks_list = [\n",
    "    callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
    "    callbacks.ModelCheckpoint(model_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6, verbose=1)\n",
    "]\n",
    "\n",
    "# 6. Train\n",
    "print(\"\\nTraining optimized model...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 7. Save training history\n",
    "with open(f'../models/training_history_{timestamp}.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "print(f\"\\nModel saved to: {model_path}\")\n",
    "print(f\"Training history saved to: ../models/training_history_{timestamp}.pkl\")\n",
    "\n",
    "# 8. Final Accuracy Report\n",
    "print(f\"\\nFinal Train Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Final Val Accuracy: {history.history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af366911-9ad6-4b37-bece-0e2b4248e99f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myEnv]",
   "language": "python",
   "name": "conda-env-myEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
